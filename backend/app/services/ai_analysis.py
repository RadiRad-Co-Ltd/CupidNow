import re
import json
import logging
import os

logger = logging.getLogger(__name__)

# Lazy imports to reduce baseline memory
# snownlp, groq, google-genai are imported on first use
from app.services.parser import Message
from app.services.text_analysis import STOP_WORDS

_groq_client = None
_gemini_client = None

_NOISE_RE = re.compile(r"^[\d\W\s]+$|^(.)\1+$")


def _compute_base_score(
    basic_stats: dict | None,
    reply_behavior: dict | None,
    cold_wars: list | None,
) -> tuple[int, dict[str, int]]:
    """Compute a 0-100 base score from quantitative data.

    Returns (base_score, dimensions_dict) where dimensions_dict contains
    per-dimension scores for transparency in the AI prompt.
    """
    # â”€â”€ 1. äº’å‹•é »ç‡ (25%) â”€â”€
    freq_score = 50
    if basic_stats:
        mc = basic_stats.get("messageCount", {})
        total_msgs = mc.get("total", 0)
        dr = basic_stats.get("dateRange", {})
        total_days = max(dr.get("totalDays", 1), 1)
        msgs_per_day = total_msgs / total_days

        # Score curve: 0â†’20, 5â†’40, 15â†’60, 30â†’75, 60â†’90, 100+â†’95
        if msgs_per_day >= 100:
            freq_score = 95
        elif msgs_per_day >= 60:
            freq_score = 90
        elif msgs_per_day >= 30:
            freq_score = 75 + (msgs_per_day - 30) / 30 * 15
        elif msgs_per_day >= 15:
            freq_score = 60 + (msgs_per_day - 15) / 15 * 15
        elif msgs_per_day >= 5:
            freq_score = 40 + (msgs_per_day - 5) / 10 * 20
        else:
            freq_score = 20 + msgs_per_day / 5 * 20

        # Call bonus
        cs = basic_stats.get("callStats", {})
        if cs.get("completedCalls", 0) > 0:
            freq_score = min(100, freq_score + 5)

    # â”€â”€ 2. ä¸»å‹•å¹³è¡¡ (20%) â”€â”€
    balance_score = 50
    if basic_stats:
        mc = basic_stats.get("messageCount", {})
        person_counts = [v for k, v in mc.items() if k != "total" and isinstance(v, int)]
        if len(person_counts) >= 2:
            mn, mx = min(person_counts), max(person_counts)
            if mx > 0:
                balance_score = round(mn / mx * 100)

    # â”€â”€ 3. å›è¦†é»˜å¥‘ (25%) â”€â”€
    reply_score = 50
    if reply_behavior:
        irr = reply_behavior.get("instantReplyRate", {})
        lor = reply_behavior.get("leftOnRead", {})

        # Average instant reply rate across persons
        rates = [v for v in irr.values() if isinstance(v, (int, float))]
        avg_irr = sum(rates) / len(rates) * 100 if rates else 50

        # Left-on-read penalty: each occurrence -3, capped at -30
        total_lor = sum(v for v in lor.values() if isinstance(v, int))
        lor_penalty = min(total_lor * 3, 30)

        reply_score = max(0, min(100, round(avg_irr - lor_penalty)))

    # â”€â”€ 4. ç©©å®šåº¦ (15%) â”€â”€
    cw_count = len(cold_wars) if cold_wars else 0
    if cw_count == 0:
        stability_score = 95
    elif cw_count == 1:
        stability_score = 75
    elif cw_count == 2:
        stability_score = 60
    else:
        stability_score = 45

    # â”€â”€ 5. è¯ç¹«æ·±åº¦ (15%) â”€â”€
    depth_score = 50
    if basic_stats:
        cs = basic_stats.get("callStats", {})
        total_call_min = cs.get("totalDurationSeconds", 0) / 60
        # Call minutes bonus: +1 per 5 min, cap +25
        call_bonus = min(round(total_call_min / 5), 25)

        # Longest streak bonus (from dateRange or basic stats)
        # Use total days as proxy for commitment duration
        dr = basic_stats.get("dateRange", {})
        total_days = dr.get("totalDays", 0)
        streak_bonus = min(round(total_days / 10), 25)

        depth_score = min(100, 50 + call_bonus + streak_bonus)

    dimensions = {
        "äº’å‹•é »ç‡": round(freq_score),
        "ä¸»å‹•å¹³è¡¡": round(balance_score),
        "å›è¦†é»˜å¥‘": round(reply_score),
        "ç©©å®šåº¦": stability_score,
        "è¯ç¹«æ·±åº¦": round(depth_score),
    }

    base = round(
        freq_score * 0.25
        + balance_score * 0.20
        + reply_score * 0.25
        + stability_score * 0.15
        + depth_score * 0.15
    )
    base = max(0, min(100, base))

    return base, dimensions


def _is_meaningful(content: str) -> bool:
    """Check if a message has real content worth sending to AI.

    Uses text length and word-level filtering. Messages with â‰¥3 Chinese
    characters that aren't pure noise are considered meaningful, even if
    individual words are common (e.g. "æˆ‘å¥½æƒ³ä½ å–”" is meaningful).
    """
    text = content.strip()
    if len(text) <= 1:
        return False
    if _NOISE_RE.match(text):
        return False

    # Messages with enough Chinese characters are likely meaningful
    cjk_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    if cjk_chars >= 3:
        return True

    # For short/mixed messages, check for substantive words
    from app.services.segmenter import cut
    words = cut(text)
    substantive = [
        w for w in words
        if len(w) >= 2
        and w not in STOP_WORDS
        and not re.match(r"^[\d\W]+$", w)
        and not re.match(r"^(.)\1+$", w)
    ]
    return len(substantive) >= 1


def _sentiment_intensity(content: str) -> float:
    """Return 0~0.5: how emotionally charged this message is.

    SnowNLP returns 0 (negative) ~ 1 (positive).
    Intensity = distance from neutral (0.5).
    Strong positive (0.95) â†’ 0.45, strong negative (0.05) â†’ 0.45
    Neutral (0.50) â†’ 0.0
    """
    try:
        from snownlp import SnowNLP
        score = SnowNLP(content).sentiments
        return abs(score - 0.5)
    except Exception:
        return 0.0


def _get_groq_client():
    global _groq_client
    if _groq_client is None:
        from groq import AsyncGroq
        _groq_client = AsyncGroq()
    return _groq_client


def _get_gemini_client():
    global _gemini_client
    if _gemini_client is None:
        from google import genai
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            return None
        _gemini_client = genai.Client(api_key=api_key)
    return _gemini_client


def _message_tfidf_score(words: list[str], word_idf: dict[str, float]) -> float:
    """Sum of IDF scores for non-stop words in a message."""
    return sum(word_idf.get(w, 0) for w in words if len(w) >= 2 and w not in STOP_WORDS)


def sample_messages(
    messages: list[Message],
    msg_words: list[list[str]] | None = None,
    word_idf: dict[str, float] | None = None,
    max_tfidf: int = 1500,
    max_final: int = 800,
) -> list[Message]:
    """Two-stage sampling: TF-IDF top content â†’ SnowNLP top sentiment.

    1. Filter meaningful messages
    2. Score by TF-IDF (sum of word IDF scores) â†’ keep top max_tfidf
    3. Score by SnowNLP sentiment intensity â†’ keep top max_final
    4. Re-sort chronologically for AI
    """
    if not messages:
        return []

    # Phase 1: filter meaningful messages, pair with word lists
    if msg_words and len(msg_words) == len(messages):
        meaningful = [
            (m, words) for m, words in zip(messages, msg_words)
            if m.msg_type == "text" and _is_meaningful(m.content)
        ]
    else:
        meaningful = [
            (m, []) for m in messages
            if m.msg_type == "text" and _is_meaningful(m.content)
        ]

    logger.info("sample_messages: %d total â†’ %d meaningful", len(messages), len(meaningful))

    # Phase 2: if within budget, return all
    if len(meaningful) <= max_final:
        return [m for m, _ in meaningful]

    # Phase 3: TF-IDF score â†’ top max_tfidf
    if word_idf and len(meaningful) > max_tfidf:
        scored = [(m, _message_tfidf_score(words, word_idf)) for m, words in meaningful]
        scored.sort(key=lambda x: x[1], reverse=True)
        tfidf_selected = [(m, s) for m, s in scored[:max_tfidf]]
        logger.info("sample_messages: TF-IDF %d â†’ %d", len(meaningful), len(tfidf_selected))
    else:
        tfidf_selected = [(m, 0) for m, _ in meaningful]

    # Phase 4: SnowNLP sentiment intensity â†’ top max_final
    sentiment_scored = [(m, _sentiment_intensity(m.content)) for m, _ in tfidf_selected]
    sentiment_scored.sort(key=lambda x: x[1], reverse=True)
    final = [m for m, _ in sentiment_scored[:max_final]]
    logger.info("sample_messages: SnowNLP â†’ %d final", len(final))

    # Phase 5: re-sort chronologically
    final.sort(key=lambda m: m.timestamp)
    return final


def _format_stats_block(stats: dict | None) -> str:
    """Format quantitative stats into a concise block for the AI prompt."""
    if not stats:
        return ""

    lines = ["â”€â”€ é‡åŒ–æ•¸æ“šï¼ˆä¾›è©•åˆ†åƒè€ƒï¼‰â”€â”€"]

    if "basicStats" in stats:
        bs = stats["basicStats"]
        mc = bs.get("messageCount", {})
        lines.append(f"ç¸½è¨Šæ¯æ•¸ï¼š{mc.get('total', 0):,}")
        persons = [k for k in mc if k != "total"]
        for p in persons:
            lines.append(f"  {p}ï¼š{mc.get(p, 0):,} å‰‡")
        dr = bs.get("dateRange", {})
        lines.append(f"èŠå¤©å¤©æ•¸ï¼š{dr.get('totalDays', 0)} å¤©ï¼ˆ{dr.get('start', '')} ~ {dr.get('end', '')}ï¼‰")
        cs = bs.get("callStats", {})
        if cs.get("totalCalls", 0) > 0:
            avg_min = round(cs.get("avgDurationSeconds", 0) / 60)
            lines.append(f"é€šè©±ï¼š{cs['completedCalls']} é€šï¼Œå¹³å‡ {avg_min} åˆ†é˜")

    if "replyBehavior" in stats:
        rb = stats["replyBehavior"]
        irr = rb.get("instantReplyRate", {})
        for p, rate in irr.items():
            lines.append(f"{p} ç§’å›ç‡ï¼š{round(rate * 100)}%")
        art = rb.get("avgReplyTime", {})
        for p, sec in art.items():
            lines.append(f"{p} å¹³å‡å›è¦†æ™‚é–“ï¼š{round(sec / 60, 1)} åˆ†é˜")
        lor = rb.get("leftOnRead", {})
        for p, cnt in lor.items():
            lines.append(f"{p} å·²è®€ä¸å›æ¬¡æ•¸ï¼š{cnt}")

    if "coldWars" in stats:
        cw = stats["coldWars"]
        if cw:
            lines.append(f"å†·æˆ°/ä½æ½®æœŸï¼š{len(cw)} æ¬¡")
        else:
            lines.append("å†·æˆ°/ä½æ½®æœŸï¼š0 æ¬¡")

    if "textAnalysis" in stats:
        ta = stats["textAnalysis"]
        wc = ta.get("wordCloud", {})
        if wc:
            lines.append("")
            lines.append("â”€â”€ é›™æ–¹é«˜é »è©ï¼ˆå·²å»é™¤åœç”¨è©ï¼Œå«å‡ºç¾æ¬¡æ•¸ï¼‰â”€â”€")
            for person, words in wc.items():
                top = words[:30]
                if top:
                    items = ", ".join(f"{w['word']}({w['count']})" for w in top)
                    lines.append(f"{person}ï¼š{items}")

    return chr(10).join(lines)


def build_prompt(
    messages: list[Message], persons: list[str],
    stats: dict | None = None, interest_context: str = "",
    base_score: int | None = None, dimensions: dict[str, int] | None = None,
) -> str:
    p1 = persons[0]
    p2 = persons[1] if len(persons) > 1 else "Person2"

    # Split messages by person for context
    p1_lines, p2_lines = [], []
    for m in messages:
        content = m.content[:80] if len(m.content) > 80 else m.content
        line = f"[{m.timestamp.strftime('%m/%d %H:%M')}] {content}"
        if m.sender == p1:
            p1_lines.append(line)
        else:
            p2_lines.append(line)

    # Also build interleaved timeline for context
    timeline = []
    for m in messages:
        content = m.content[:80] if len(m.content) > 80 else m.content
        timeline.append(f"[{m.timestamp.strftime('%m/%d %H:%M')}] {m.sender}: {content}")

    stats_block = _format_stats_block(stats)

    # Base score block for AI prompt
    if base_score is not None and dimensions:
        lo = max(base_score - 15, 0)
        hi = min(base_score + 15, 100)
        dim_parts = "  ".join(f"{k}ï¼š{v}" for k, v in dimensions.items())
        base_score_block = (
            f"\nâ”€â”€ é‡åŒ–åŸºåº•åˆ†ï¼š{base_score} / 100 â”€â”€\n"
            f"  {dim_parts}\n"
            f"ä½ çš„æœ€çµ‚ loveScore.score å¿…é ˆåœ¨ {lo}~{hi} ä¹‹é–“ï¼ˆåŸºåº•åˆ† Â±15ï¼‰ã€‚\n"
            f"åªæœ‰åœ¨å°è©±æƒ…æ„Ÿå“è³ªæ˜é¡¯åé›¢æ•¸æ“šæ™‚æ‰å¤§å¹…èª¿æ•´ã€‚\n"
        )
    else:
        base_score_block = ""

    # Interest context block (TF-IDF distinctive words + example sentences)
    interest_block = f"\n\n{interest_context}\n" if interest_context else ""

    return f"""ä½ æ˜¯ä¸€ä½è¶…ç´šæ‡‚æ„Ÿæƒ…çš„é–¨èœœåˆ†æå¸«ï¼Œèªªè©±æ´»æ½‘ã€å¸¶é»ä¿çš®ï¼Œæ“…é•·å¾èŠå¤©è¨˜éŒ„ä¸­çœ‹å‡ºå…©å€‹äººä¹‹é–“çš„å¾®å¦™äº’å‹•å’ŒåŒ–å­¸åæ‡‰ã€‚

ä»¥ä¸‹æ˜¯ {p1} å’Œ {p2} çš„èŠå¤©è¨˜éŒ„ã€‚

âš ï¸ é—œä¿‚åˆ¤æ–·è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼Œè«‹ä»”ç´°åˆ†æå¾Œå†ä¸‹çµè«–ï¼‰ï¼š
å…©äººå¯èƒ½æ˜¯ä»»ä½•é—œä¿‚â€”â€”åŒäº‹ã€æœ‹å‹ã€ç¶²å‹ã€æ›–æ˜§å°è±¡ã€æƒ…ä¾¶ã€è€å¤«è€å¦»ã€‚ä¸è¦å› ç‚ºå°è©±ä¸­æ—¥å¸¸ç‘£äº‹å¤šå°±ç›´æ¥å‡è¨­æ˜¯ã€Œè€å¤«è€å¦»ã€æˆ–ã€Œç©©å®šäº¤å¾€ã€ã€‚è«‹æ ¹æ“šä»¥ä¸‹ç·šç´¢ç¶œåˆåˆ¤æ–·ï¼š
- ç¨±å‘¼æ–¹å¼ï¼šç”¨ã€Œå¯¶è²/è¦ªæ„›çš„/è€å…¬è€å©†ã€vsã€Œå­¸é•·/åŒäº‹åã€vsã€Œä½ ã€å·®ç•°å¾ˆå¤§
- è©±é¡Œé‚Šç•Œï¼šæƒ…ä¾¶æœƒèŠç§å¯†å¿ƒäº‹ã€æ’’å¬Œåƒé†‹ï¼›åŒäº‹æœ‹å‹ä¸»è¦èŠå·¥ä½œã€å…±åŒè©±é¡Œ
- è‚¢é«”èªè¨€æš—ç¤ºï¼šæœ‰æ²’æœ‰ã€ŒæŠ±æŠ±/è¦ªè¦ª/æƒ³ä½ ã€ç­‰è¦ªå¯†è¡¨é”
- äº’å‹•é »ç‡èˆ‡æ™‚æ®µï¼šæ·±å¤œèŠå¤©ã€æ¯å¤©æ—©æ™šå•å€™ vs åªåœ¨ä¸Šç­æ™‚é–“èŠ
- æƒ…æ„Ÿæ¿ƒåº¦ï¼šæœ‰æ²’æœ‰æ˜é¡¯çš„æ›–æ˜§ã€åƒé†‹ã€æƒ³å¿µã€å¿ƒç–¼ç­‰æƒ…ç·’

åˆ¤æ–·å‡ºé—œä¿‚éšæ®µå¾Œï¼Œè©•åˆ†å’Œå»ºè­°éƒ½è¦ç¬¦åˆè©²éšæ®µçš„åˆç†æœŸå¾…ã€‚ä¾‹å¦‚ï¼š
- åŒäº‹/æœ‹å‹ï¼šä¸éœ€è¦æœ‰ç”œèœœè¨Šæ¯ï¼Œé‡é»çœ‹äº’å‹•å“è³ªå’Œé»˜å¥‘
- æ›–æ˜§ä¸­ï¼šçœ‹è©¦æ¢ã€æ”¾é›»ã€ä¸»å‹•ç¨‹åº¦
- ç©©å®šäº¤å¾€ï¼šçœ‹æ—¥å¸¸é—œå¿ƒã€è¡çªè™•ç†ã€æƒ…æ„Ÿç¶­ç¹«
- è€å¤«è€å¦»ï¼šæ—¥å¸¸ç‘£äº‹å¤šä½†ä»æœ‰é—œå¿ƒæ˜¯æ­£å¸¸çš„ï¼Œä¸æ‰£åˆ†

æ³¨æ„ï¼šè©•åˆ†æ™‚è«‹åŒæ™‚åƒè€ƒä¸‹æ–¹çš„é‡åŒ–æ•¸æ“šï¼Œä¾‹å¦‚ç§’å›ç‡é«˜ä»£è¡¨ä¸»å‹•æ€§å¼·ã€å·²è®€ä¸å›å¤šä»£è¡¨å¯èƒ½æœ‰å†·æ·¡å‚¾å‘ã€é€šè©±é »ç¹ä»£è¡¨æ„Ÿæƒ…è¼ƒè¦ªå¯†ã€‚

{stats_block}
{base_score_block}
â”€â”€ {p1} èªªçš„è©± â”€â”€
{chr(10).join(p1_lines[-80:])}

â”€â”€ {p2} èªªçš„è©± â”€â”€
{chr(10).join(p2_lines[-80:])}

â”€â”€ å®Œæ•´å°è©±æ™‚é–“è»¸ï¼ˆçœ‹äº’å‹•ç¯€å¥ï¼‰â”€â”€
{chr(10).join(timeline[-120:])}
{interest_block}
âš ï¸ sharedInterests å¡«å¯«è¦å‰‡ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š
items å¿…é ˆæ˜¯å°è©±ä¸­å‡ºç¾çš„ã€å…·é«”å°ˆæœ‰åè©ã€‘ï¼Œä¸è¦å¯«æ¨¡ç³Šçš„é¡åˆ¥è©ã€‚
âœ… æ­£ç¢ºç¯„ä¾‹ï¼šå¯„ç”Ÿä¸Šæµã€é»‘æš—æ¦®è€€ã€é¬¼æ»…ä¹‹åˆƒã€å‘¨æ°å€«ã€äº”æœˆå¤©ã€æ™´å¤©ã€é¼æ³°è±ã€ä¹ä»½ã€åŒ—æŠ•æº«æ³‰ã€æ˜Ÿå·´å…‹ã€å°ç¾ï¼ˆæœ‹å‹æš±ç¨±ï¼‰
âŒ éŒ¯èª¤ç¯„ä¾‹ï¼šéŸ“åŠ‡ã€é›»å½±ã€éŸ³æ¨‚ã€æ•£æ­¥ã€å¥èº«ã€ç”œé»ï¼ˆé€™äº›æ˜¯é¡åˆ¥è©ä¸æ˜¯å…·é«”åç¨±ï¼Œçµ•å°ä¸è¦å¯«ï¼‰
å¦‚æœå°è©±ä¸­æ²’æåˆ°æŸé¡åˆ¥çš„å…·é«”åç¨±ï¼Œè©²é¡åˆ¥å°±ä¸è¦åˆ—å‡ºã€‚
å…±åŒæœ‹å‹ï¼šå°è©±ä¸­é »ç¹æåˆ°çš„ç¬¬ä¸‰äººåå­—æˆ–æš±ç¨±å¯ä½œç‚ºä¸€å€‹é¡åˆ¥ã€‚

è«‹ç¶œåˆä»¥ä¸Šå…§å®¹ï¼Œå›å‚³ä»¥ä¸‹ JSONï¼ˆä¸è¦åŠ  markdown code blockã€ä¸è¦åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "loveScore": {{
    "score": <0-100 å¿ƒå‹•æŒ‡æ•¸ã€‚ç³»çµ±å·²æ ¹æ“šé‡åŒ–æ•¸æ“šç®—å‡ºåŸºåº•åˆ†ï¼ˆè¦‹ä¸Šæ–¹ï¼‰ï¼Œä½ çš„åˆ†æ•¸å¿…é ˆåœ¨åŸºåº•åˆ† Â±15 ç¯„åœå…§ã€‚è«‹æ ¹æ“šå°è©±çš„æƒ…æ„Ÿå“è³ªå¾®èª¿ï¼šç”œèœœäº’å‹•å¤šå¯åŠ åˆ†ï¼Œå†·æ·¡æ•·è¡å¯æ‰£åˆ†>,
    "comment": "<80-120 å­—çš„æ´»æ½‘è©•èªï¼Œ2-3 å¥è©±ã€‚åƒé–¨èœœåœ¨æ—é‚Šå¹«ä½ åˆ†æï¼Œç¬¬ä¸€å¥é»å‡ºä½ å€‘çš„äº’å‹•ç‰¹è‰²æˆ–äº®é»ï¼Œç¬¬äºŒå¥å…·é«”æè¿°ä¸€å€‹è®“äººå°è±¡æ·±åˆ»çš„äº’å‹•æ¨¡å¼ï¼Œç¬¬ä¸‰å¥çµ¦å‡ºä¸€å¥æš–å¿ƒæˆ–ä¿çš®çš„ç¸½çµã€‚æ ¹æ“šé—œä¿‚éšæ®µçµ¦å‡ºä¸åŒé¢¨æ ¼çš„é»è©•ï¼ˆæ›–æ˜§æœŸå¯ä»¥ä¿çš®ï¼Œè€å¤«è€å¦»å¯ä»¥æº«é¦¨ï¼‰>"
  }},
  "sentiment": {{
    "sweet": <ç”œèœœæ’’å¬Œä½”æ¯” 0-100>,
    "flirty": <æ›–æ˜§æ”¾é›»ã€è©¦æ¢ã€èª¿æƒ…ä½”æ¯” 0-100>,
    "daily": <æŸ´ç±³æ²¹é¹½æ—¥å¸¸ä½”æ¯” 0-100>,
    "conflict": <ç«è—¥å‘³ã€å†·æ·¡ã€ä¸è€ç…©ä½”æ¯” 0-100>,
    "missing": <æƒ³å¿µã€æ¨ä¸å¾—ã€åœ¨æ„å°æ–¹ä½”æ¯” 0-100>
  }},
  "goldenQuotes": {{
    "sweetest": [
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}},
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}},
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}}
    ],
    "funniest": [
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}},
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}},
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}}
    ],
    "mostTouching": [
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}},
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}},
      {{"quote": "<åŸæ–‡>", "sender": "<èª°èªªçš„>", "date": "<å¹¾æœˆ/å¹¾æ—¥>"}}
    ]
  }},
  "relationshipType": "<ç”¨ä¸€å€‹è©æè¿°ä½ åˆ¤æ–·çš„é—œä¿‚é¡å‹ï¼šåŒäº‹ã€æœ‹å‹ã€ç¶²å‹ã€æ›–æ˜§ä¸­ã€ç†±æˆ€æœŸã€ç©©å®šäº¤å¾€ã€è€å¤«è€å¦»>",
  "insight": "<100 å­—ä»¥å…§ï¼Œç”¨æ´»æ½‘çš„èªæ°£æè¿° {p1} å’Œ {p2} çš„é—œä¿‚éšæ®µå’Œäº’å‹•æ¨¡å¼ã€‚å…ˆæ˜ç¢ºé»å‡ºä½ åˆ¤æ–·çš„é—œä¿‚é¡å‹å’Œä¾æ“šï¼Œå†æè¿°äº’å‹•ç‰¹è‰²ã€‚æœ‹å‹/åŒäº‹å°±åˆ†æé»˜å¥‘å’Œäº’å‹•å“è³ªï¼›æ›–æ˜§æœŸåˆ†æèª°åœ¨è¿½èª°ï¼›æƒ…ä¾¶åˆ†ææ„Ÿæƒ…æ¿ƒåº¦>",
  "sharedInterests": [
    {{
      "category": "<æ„›å»çš„åœ°æ–¹ / æ„›åƒçš„æ±è¥¿ / æ„›çœ‹çš„åŠ‡ / æ„›è½çš„éŸ³æ¨‚ / å¸¸ä¸€èµ·åšçš„äº‹ / å…±åŒæœ‹å‹ / æˆ–è‡ªè¨‚>",
      "items": [{{"name": "<å…·é«”å°ˆæœ‰åè©>"}}, {{"name": "..."}}]
    }}
  ],
  "advice": [
    {{"category": "ğŸ’¬ èŠå¤©æŠ€å·§", "target": "{p1}", "content": "<æ ¹æ“š {p1} çš„èŠå¤©é¢¨æ ¼ï¼Œçµ¦ä¸€å¥å…·é«”ã€å¯åŸ·è¡Œçš„æºé€šå»ºè­°ï¼Œä¾‹å¦‚å›è¦†é€Ÿåº¦ã€è¡¨é”æ–¹å¼ã€ä¸»å‹•ç¨‹åº¦ç­‰>"}},
    {{"category": "ğŸ’¬ èŠå¤©æŠ€å·§", "target": "{p2}", "content": "<æ ¹æ“š {p2} çš„èŠå¤©é¢¨æ ¼ï¼Œçµ¦ä¸€å¥å…·é«”ã€å¯åŸ·è¡Œçš„æºé€šå»ºè­°>"}},
    {{"category": "â¤ï¸ æ„Ÿæƒ…å¢æº«", "target": "å…©äºº", "content": "<ä¸€å€‹å…·é«”çš„äº’å‹•å»ºè­°ï¼Œä¾‹å¦‚å¯ä»¥å˜—è©¦çš„è©±é¡Œã€å°éŠæˆ²ã€æˆ–è®“å°è©±æ›´æœ‰æº«åº¦çš„æ–¹æ³•>"}},
    {{"category": "ğŸ¯ ç´„æœƒéˆæ„Ÿ", "target": "å…©äºº", "content": "<æ ¹æ“šå°è©±ä¸­æåˆ°çš„åœ°é»ã€é£Ÿç‰©ã€èˆˆè¶£ï¼Œæ¨è–¦ä¸€å€‹å…·é«”çš„ç´„æœƒæˆ–æ´»å‹•é»å­>"}},
    {{"category": "âš¡ é»˜å¥‘å‡ç´š", "target": "å…©äºº", "content": "<é‡å°ç›®å‰äº’å‹•æ¨¡å¼ä¸­å¯ä»¥æ”¹å–„çš„åœ°æ–¹ï¼Œä¾‹å¦‚å›è¦†ç¯€å¥ä¸åŒæ­¥ã€è©±é¡Œæ·±åº¦ä¸å¤ ã€æˆ–æŸæ–¹å¤ªè¢«å‹•ç­‰ï¼Œçµ¦å‡ºå…·é«”å»ºè­°>"}},
    {{"category": "ğŸŒŸ é—œä¿‚æˆé•·", "target": "å…©äºº", "content": "<æ ¹æ“šåˆ¤æ–·å‡ºçš„é—œä¿‚éšæ®µï¼Œçµ¦ä¸€å€‹å¹«åŠ©é—œä¿‚é€²éšçš„å»ºè­°ã€‚æ›–æ˜§æœŸï¼šæ€éº¼æ›´æ˜ç¢ºè¡¨é”å¿ƒæ„ï¼›ç©©å®šæœŸï¼šæ€éº¼ä¿æŒæ–°é®®æ„Ÿï¼›è€å¤«è€å¦»ï¼šæ€éº¼é‡æ–°æ‰¾å›å¿ƒå‹•>"}}
  ]
}}"""


class AIRateLimitError(Exception):
    """Raised when all AI providers are rate limited."""
    pass


def _parse_ai_response(text: str, provider: str) -> dict | None:
    """Parse AI response text into dict. Returns None on failure."""
    text = text.strip()

    # Try direct parse
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    # Try extracting from markdown code block
    if "```" in text:
        try:
            json_str = text.split("```")[1]
            if json_str.startswith("json"):
                json_str = json_str[4:]
            return json.loads(json_str.strip())
        except (json.JSONDecodeError, IndexError):
            pass

    logger.error("[%s] JSON parse failed, text preview: %s", provider, text[:500])
    return None


async def _call_groq(prompt: str) -> dict | None:
    """Try Groq API. Returns parsed dict, None on parse failure, raises on rate limit."""
    client = _get_groq_client()

    try:
        response = await client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            max_tokens=3000,
            temperature=0.5,
            messages=[{"role": "user", "content": prompt}],
        )
    except Exception as e:
        if "429" in str(e) or "rate_limit" in str(e).lower():
            logger.warning("[Groq] Rate limited: %s", e)
            return None  # Signal to try fallback
        raise

    text = response.choices[0].message.content.strip()
    finish_reason = response.choices[0].finish_reason

    if finish_reason != "stop":
        logger.warning("[Groq] Response truncated (finish_reason=%s), length=%d", finish_reason, len(text))

    result = _parse_ai_response(text, "Groq")
    if result:
        logger.info("[Groq] AI analysis succeeded")
    return result


async def _call_gemini(prompt: str) -> dict | None:
    """Try Google Gemini API as fallback."""
    client = _get_gemini_client()
    if client is None:
        logger.warning("[Gemini] No GOOGLE_API_KEY configured, skipping")
        return None

    try:
        response = await client.aio.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
        )
    except Exception as e:
        if "429" in str(e) or "rate" in str(e).lower():
            logger.warning("[Gemini] Rate limited: %s", e)
            return None
        logger.exception("[Gemini] API call failed")
        return None

    text = response.text or ""

    result = _parse_ai_response(text, "Gemini")
    if result:
        logger.info("[Gemini] AI analysis succeeded (fallback)")
    return result


def _clamp_love_score(ai_result: dict, base_score: int | None) -> None:
    """Clamp AI loveScore to [base-15, base+15] range."""
    if base_score is None:
        return
    ls = ai_result.get("loveScore")
    if not ls or "score" not in ls:
        return
    score = ls["score"]
    if not isinstance(score, (int, float)):
        return
    lo = max(base_score - 15, 0)
    hi = min(base_score + 15, 100)
    ls["score"] = max(lo, min(hi, int(score)))


async def analyze_with_ai(
    messages: list[Message], persons: list[str], stats: dict | None = None,
    interest_context: str = "",
    msg_words: list[list[str]] | None = None,
    word_idf: dict[str, float] | None = None,
    base_score: int | None = None,
    dimensions: dict[str, int] | None = None,
) -> dict:
    """Call AI API with Groq â†’ Gemini fallback chain."""
    sampled = sample_messages(messages, msg_words=msg_words, word_idf=word_idf)
    if not sampled:
        return _fallback_result()

    prompt = build_prompt(
        sampled, persons, stats, interest_context=interest_context,
        base_score=base_score, dimensions=dimensions,
    )

    # 1. Try Groq (faster)
    result = await _call_groq(prompt)
    if result:
        _clamp_love_score(result, base_score)
        return result

    # 2. Fallback to Gemini
    logger.info("Groq unavailable, falling back to Gemini")
    result = await _call_gemini(prompt)
    if result:
        _clamp_love_score(result, base_score)
        return result

    # 3. Both failed
    logger.error("All AI providers failed")
    raise AIRateLimitError("AI åˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦")


def _fallback_result() -> dict:
    return {
        "loveScore": {"score": 50, "comment": "è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•å®Œæ•´åˆ†æ"},
        "sentiment": {"sweet": 20, "flirty": 20, "daily": 40, "conflict": 10, "missing": 10},
        "goldenQuotes": {"sweetest": [], "funniest": [], "mostTouching": []},
        "insight": "å°è©±å…§å®¹ä¸è¶³ï¼Œå»ºè­°ä¸Šå‚³æ›´é•·çš„å°è©±è¨˜éŒ„ä»¥ç²å¾—æ›´æº–ç¢ºçš„åˆ†æã€‚",
        "advice": [],
    }
